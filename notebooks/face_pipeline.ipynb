{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "import imutils\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from facelib.transformers import crop_face_bounding_box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGETYPES = ('*.bmp', '*.png', '*.jpg', '*.jpeg', '*.tif') # Supported image types\n",
    "\n",
    "\n",
    "def get_image_paths(file_root, pattern=None):\n",
    "    \"\"\" Get ordered list of filepaths\n",
    "    \"\"\"\n",
    "    file_paths = []\n",
    "    for typ in IMAGETYPES:\n",
    "        file_paths.extend(glob.glob(os.path.join(file_root,'**',typ), recursive=True))\n",
    "\n",
    "    # filter filenames\n",
    "    if pattern is not None:\n",
    "        ffiltered = []\n",
    "        ffiltered = [f for f in file_paths if pattern in os.path.split(f)[-1]]\n",
    "        file_paths = ffiltered\n",
    "        del ffiltered\n",
    "\n",
    "    file_paths.sort()\n",
    "    return file_paths\n",
    "\n",
    "\n",
    "def load_face_dataset(file_root):\n",
    "    \"\"\" Load all images and also list out the filepaths\n",
    "    \"\"\"\n",
    "    if not os.path.isdir(file_root):\n",
    "        raise FileNotFoundError(\"Face dataset file root: {} not found.\".format(file_root))\n",
    "\n",
    "    file_paths = get_image_paths(file_root)\n",
    "    \n",
    "    if len(file_paths) == 0:\n",
    "        warnings.warn(\"No image found in face dataset file root: {}\".format(file_root))\n",
    "        return []\n",
    "    \n",
    "    images = [cv2.imread(file_path) for file_path in file_paths]\n",
    "    return images, file_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Definition for FaceDetector\n",
    "\"\"\"\n",
    "\n",
    "imageMean = [104.0, 177.0, 123.0]\n",
    "confThresh = 0.5\n",
    "\n",
    "\n",
    "class FaceDetector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\" Face dataset transformers that detect faces in an image and yield cropped faces image\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, prototxt, caffeModel, imsize=(300,300), \n",
    "                 multiFaceMode=False, strict=False):\n",
    "        \"\"\" Initialise face detector\n",
    "\n",
    "        Args:\n",
    "            .. prototxt   (str/path): path to prototxt file defining the architecture\n",
    "            .. caffeModel (str/path): path to checkpoint file of pretrained caffe model\n",
    "            .. imsize   (Tuple[int]): height and width of image blob\n",
    "            .. multiFaceMode  (bool): whether to detect only multiple or single face for each image\n",
    "            .. strict (bool) : if no face detected, raise error\n",
    "        \"\"\"\n",
    "        if not os.path.isfile(prototxt):\n",
    "            raise FileNotFoundError(\"Prototxt file: {} not found.\".format(prototxt))\n",
    "        \n",
    "        if not os.path.isfile(caffeModel):\n",
    "            raise FileNotFoundError(\"CaffeModel file: {} not found.\".format(caffeModel))\n",
    "\n",
    "        self.imsize = imsize\n",
    "        self.multiFaceMode = multiFaceMode\n",
    "        self.detector = cv2.dnn.readNetFromCaffe(prototxt, caffeModel=caffeModel)\n",
    "\n",
    "    def fit(self, *args, **kwargs):\n",
    "        # unused but need to satisfy abstraction rule\n",
    "        return self\n",
    "\n",
    "    def transform(self, images):\n",
    "        \"\"\" Perform face detection and cropping for batch of images\n",
    "        \n",
    "        Args:\n",
    "            .. images (np.ndarray): array of images in tensor form of shape [C,H,W]\n",
    "\n",
    "        Returns:\n",
    "            .. faces (np.ndarray or List[List[np.ndarray]]): array of images in numpy tensor.\n",
    "                    If multiFaceMode false, output is tensor of shape: [N,C,H,W]\n",
    "                    If multiFaceMode true, output is array of cropped faces.\n",
    "        \"\"\"\n",
    "        if self.multiFaceMode == True:\n",
    "            rects = [self._detect_multi_faces(image) for image in tqdm(images)]\n",
    "        else:\n",
    "            rects = np.stack([self._detect_single_face(image) for image in tqdm(images)])\n",
    "        return images, rects\n",
    "\n",
    "    # -------------------\n",
    "    # Detector helper\n",
    "    # -------------------\n",
    "\n",
    "    def _detect_single_face(self, image):\n",
    "        \"\"\" Apply detection assuming only one face per image\n",
    "        \n",
    "        Args:\n",
    "            .. image (np.ndarray): images in numpy tensor form of shape [C,H,W]\n",
    "        \n",
    "        Returns:\n",
    "            .. face (np.ndarray or None): image in numpy tensor of shape [C,H,W]. None if no face\n",
    "        \"\"\"\n",
    "        h, w = image.shape[:2]\n",
    "\n",
    "        # construct a blob from the image\n",
    "        imageBlob = cv2.dnn.blobFromImage(cv2.resize(image, self.imsize), 1.0, self.imsize, imageMean)\n",
    "\n",
    "        # apply OpenCV's deep learning-based face detector to localize\n",
    "        # faces in the input image\n",
    "        self.detector.setInput(imageBlob)\n",
    "        detections = self.detector.forward()\n",
    "        \n",
    "        # ensure at least one face was found\n",
    "        if len(detections) > 0:\n",
    "            # we're making the assumption that each image has only ONE\n",
    "            # face, so find the bounding box with the largest probability\n",
    "            i = np.argmax(detections[0, 0, :, 2])\n",
    "            confidence = detections[0, 0, i, 2]\n",
    "\n",
    "            # filter out weak detections\n",
    "            if confidence > confThresh:\n",
    "                # compute the (x, y)-coordinates of the bounding box for\n",
    "                # the face\n",
    "                box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "                (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "\n",
    "                # grab the ROI dimensions\n",
    "                (fH, fW) = endY - startY, endX - startX\n",
    "\n",
    "                # ensure the face width and height are sufficiently large\n",
    "                if fW > 40 and fH > 40:\n",
    "                    rect = dlib.rectangle(startX, startY, startX+fW, startY+fH)\n",
    "                    return rect\n",
    "\n",
    "        if strict:\n",
    "            raise ValueError(\"Unable to detect face during FaceDetection in one of the image passed.\\n\"\n",
    "                             \"Ensure that image is clean and has face in it. \"\n",
    "                             \"You can also \\n increase the threshold.\")\n",
    "        return None\n",
    "    \n",
    "    def _detect_multi_faces(self, image):\n",
    "        \"\"\" Apply detection assuming only one face per image\n",
    "        \n",
    "        Args:\n",
    "            .. image (np.ndarray): images in numpy tensor form of shape [C,H,W]\n",
    "        \n",
    "        Returns:\n",
    "            .. face_images (np.ndarray or None): array of faces images of shape \n",
    "        \"\"\"\n",
    "        blob = cv2.dnn.blobFromImage(cv2.resize(image, self.imsize, 1.0, self.imsize, imageMean))\n",
    "\n",
    "        # apply OpenCV's deep learning-based face detector to localize\n",
    "        # faces in the input image\n",
    "        self.detector.setInput(imageBlob)\n",
    "        detections = self.detector.forward()\n",
    "\n",
    "        rects = []\n",
    "        \n",
    "        # loop over the detections\n",
    "        for i in range(0, detections.shape[2]):\n",
    "            # extract the confidence (i.e., probability) associated with\n",
    "            # the prediction\n",
    "            confidence = detections[0, 0, i, 2]\n",
    "\n",
    "            # filter out weak detections with less than 50% confidence\n",
    "            if confidence > 0.5:\n",
    "                # compute the (x, y)-coordinates of the bounding box for\n",
    "                # the face\n",
    "                box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "                (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "\n",
    "                # grab the ROI dimensions\n",
    "                (fH, fW) = endY - startY, endX - startX\n",
    "\n",
    "                # ensure the face width and height are sufficiently large\n",
    "                if fW < 40 or fH < 40:\n",
    "                    continue\n",
    "\n",
    "                rect = dlib.rectangle(startX, startY, startX+fW, startY+fH)\n",
    "                rects.append(rect)\n",
    "\n",
    "        return rects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../data/temp/\"\n",
    "\n",
    "images, file_paths = load_face_dataset(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define file paths to model files\n",
    "prototxt = '../models/deploy.prototxt'\n",
    "caffeModel = '../models/res10_300x300_ssd_iter_140000.caffemodel'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe1 = Pipeline([\n",
    "    ('facedetector', FaceDetector(prototxt, caffeModel)),\n",
    "    ('cropface', crop_face_bounding_box())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pipe1.fit_transform(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
